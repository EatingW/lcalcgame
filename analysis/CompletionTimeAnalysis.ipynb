{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the iso8601 module, unfortunately, to do robust date parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "import iso8601"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the folder in which the JSON log files are kept. They will be read and concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"userlogs/lauren\"\n",
    "events = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(os.path.join(folder, \"*.json\"))\n",
    "filenames.sort()\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "        if \"static\" in filename: # Add 'static' if file was downloaded locally, not generated by the node.js server.\n",
    "            txt = f.read()\n",
    "            es = json.loads(txt)\n",
    "            for e in es:\n",
    "                events.append( {\"0\":e[0], \"1\":e[1]} )\n",
    "        else:\n",
    "            for line in f:\n",
    "                events.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tasks = [event for event in events if event[\"0\"] in (\"startTask\", \"endTask\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userlogs/lauren/static_log_1507229018171.json']\n"
     ]
    }
   ],
   "source": [
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to synthesize an endTask for the last level, since normally this is only recorded on level transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_level = tasks[-1][\"1\"][\"quest_id\"]\n",
    "if tasks[-1][\"0\"] != \"endTask\":\n",
    "    for event in events[::-1]:\n",
    "        if event[\"1\"].get(\"quest_id\") == last_level:\n",
    "            fake_task = event.copy()\n",
    "            fake_task[\"0\"] = \"endTask\"\n",
    "            tasks.append(fake_task)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 already has a start time.\n"
     ]
    }
   ],
   "source": [
    "completion_times = collections.defaultdict(list)\n",
    "start_times = {}\n",
    "for task in tasks:\n",
    "    if task[\"0\"] == \"startTask\":\n",
    "        quest_id = task[\"1\"][\"quest_id\"]\n",
    "        if quest_id in start_times:\n",
    "            print(\"Task\", quest_id, \"already has a start time.\")\n",
    "        if \"timestamp\" in task:\n",
    "            start_times[quest_id] = iso8601.parse_date(ts)\n",
    "        else:\n",
    "            start_times[quest_id] = datetime.datetime.fromtimestamp(task[\"1\"][\"client_timestamp\"] / 1000)\n",
    "    elif task[\"0\"] == \"endTask\":\n",
    "        quest_id = task[\"1\"][\"quest_id\"]\n",
    "        start_time = start_times.get(quest_id)\n",
    "        if not start_time:\n",
    "            print(\"WARNING: Level\", quest_id, \"does not have a start time.\")\n",
    "            continue\n",
    "        if \"timestamp\" in task:\n",
    "            end_time = iso8601.parse_date(task[\"timestamp\"])\n",
    "        else:\n",
    "            end_time = datetime.datetime.fromtimestamp(task[\"1\"][\"client_timestamp\"] / 1000)\n",
    "        completion_times[quest_id].append((end_time - start_time).total_seconds())\n",
    "        del start_times[quest_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_times = {}\n",
    "for level_id, times in completion_times.items():\n",
    "    total_times[level_id] = sum(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.25\n",
      "10.765\n",
      "13.334\n",
      "4.276\n",
      "33.019999999999996\n",
      "36.713\n",
      "161.956\n",
      "16.387\n",
      "15.404\n",
      "12.036\n",
      "10.541\n",
      "17.841\n",
      "53.760999999999996\n",
      "272.827\n",
      "8.542\n",
      "10.843\n",
      "18.596\n",
      "22.369\n",
      "76.08500000000001\n",
      "14.884\n",
      "124.786\n",
      "28.321\n",
      "121.67099999999999\n",
      "18.596\n",
      "32.256\n",
      "17.6\n",
      "52.766999999999996\n",
      "234.671\n",
      "168.243\n",
      "95.351\n",
      "153.834\n",
      "219.29199999999997\n",
      "7.325\n",
      "48.737\n",
      "37.315\n",
      "21.019\n",
      "78.473\n",
      "44.733\n",
      "138.659\n",
      "92.958\n",
      "52.547\n",
      "24.047\n",
      "273.364\n",
      "31.127\n",
      "709.271\n"
     ]
    }
   ],
   "source": [
    "for t in total_times:\n",
    "    print(total_times[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(folder, \"output.csv\")\n",
    "with open(output_path, \"w\") as output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    for level_id, total_seconds in sorted(total_times.items(), key=lambda x: x[0]):\n",
    "        writer.writerow((level_id, \"{:.02f}\".format(total_seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='userlogs/lauren/output.csv' target='_blank'>userlogs/lauren/output.csv</a><br>"
      ],
      "text/plain": [
       "/Users/ianarawjo/Desktop/lambda_calc/analysis/userlogs/lauren/output.csv"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
