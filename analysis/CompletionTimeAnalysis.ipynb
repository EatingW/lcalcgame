{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the iso8601 module, unfortunately, to do robust date parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "import iso8601"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the folder in which the JSON log files are kept. They will be read and concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"userlogs/jeremy\"\n",
    "events = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(os.path.join(folder, \"*.json\"))\n",
    "filenames.sort()\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "        if \"static\" in filename: # Add 'static' if file was downloaded locally, not generated by the node.js server.\n",
    "            txt = f.read()\n",
    "            es = json.loads(txt)\n",
    "            for e in es:\n",
    "                events.append( {\"0\":e[0], \"1\":e[1]} )\n",
    "        else:\n",
    "            for line in f:\n",
    "                events.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tasks = [event for event in events if event[\"0\"] in (\"startTask\", \"endTask\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userlogs/jeremy/static_log_1505995872926.json']\n"
     ]
    }
   ],
   "source": [
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to synthesize an endTask for the last level, since normally this is only recorded on level transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_level = tasks[-1][\"1\"][\"quest_id\"]\n",
    "if tasks[-1][\"0\"] != \"endTask\":\n",
    "    for event in events[::-1]:\n",
    "        if event[\"1\"].get(\"quest_id\") == last_level:\n",
    "            fake_task = event.copy()\n",
    "            fake_task[\"0\"] = \"endTask\"\n",
    "            tasks.append(fake_task)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "completion_times = collections.defaultdict(list)\n",
    "start_times = {}\n",
    "for task in tasks:\n",
    "    if task[\"0\"] == \"startTask\":\n",
    "        quest_id = task[\"1\"][\"quest_id\"]\n",
    "        if quest_id in start_times:\n",
    "            print(\"Task\", quest_id, \"already has a start time.\")\n",
    "        if \"timestamp\" in task:\n",
    "            start_times[quest_id] = iso8601.parse_date(ts)\n",
    "        else:\n",
    "            start_times[quest_id] = datetime.datetime.fromtimestamp(task[\"1\"][\"client_timestamp\"] / 1000)\n",
    "    elif task[\"0\"] == \"endTask\":\n",
    "        quest_id = task[\"1\"][\"quest_id\"]\n",
    "        start_time = start_times.get(quest_id)\n",
    "        if not start_time:\n",
    "            print(\"WARNING: Level\", quest_id, \"does not have a start time.\")\n",
    "            continue\n",
    "        if \"timestamp\" in task:\n",
    "            end_time = iso8601.parse_date(task[\"timestamp\"])\n",
    "        else:\n",
    "            end_time = datetime.datetime.fromtimestamp(task[\"1\"][\"client_timestamp\"] / 1000)\n",
    "        completion_times[quest_id].append((end_time - start_time).total_seconds())\n",
    "        del start_times[quest_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_times = {}\n",
    "for level_id, times in completion_times.items():\n",
    "    total_times[level_id] = sum(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.549\n",
      "25.471\n",
      "13.929\n",
      "9.821\n",
      "10.269\n",
      "9.473\n",
      "21.622\n",
      "17.222\n",
      "6.376\n",
      "8.747\n",
      "11.582\n",
      "4.838\n",
      "8.348\n",
      "14.088\n",
      "8.336\n",
      "17.21\n",
      "22.758\n",
      "20.169\n",
      "26.13\n",
      "18.979\n",
      "18.273\n",
      "15.985\n",
      "66.249\n",
      "26.567\n",
      "9.544\n",
      "11.307\n",
      "14.613\n",
      "43.370999999999995\n",
      "197.226\n",
      "223.499\n",
      "106.986\n",
      "22.748\n",
      "20.448999999999998\n",
      "11.706\n",
      "17.297\n",
      "28.541\n",
      "16.748\n",
      "26.59\n",
      "54.178\n",
      "19.161\n",
      "27.962\n",
      "16.015\n",
      "24.868\n",
      "89.51599999999999\n",
      "160.595\n",
      "44.7\n",
      "174.756\n",
      "8.435\n",
      "61.248999999999995\n",
      "27.399\n",
      "7.937\n",
      "22.567\n",
      "13.734\n",
      "35.088\n",
      "25.225\n",
      "119.84200000000001\n",
      "28.166\n",
      "35.283\n",
      "21.559\n",
      "20.344\n",
      "77.842\n"
     ]
    }
   ],
   "source": [
    "for t in total_times:\n",
    "    print(total_times[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(folder, \"output.csv\")\n",
    "with open(output_path, \"w\") as output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    for level_id, total_seconds in sorted(total_times.items(), key=lambda x: x[0]):\n",
    "        writer.writerow((level_id, \"{:.02f}\".format(total_seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
